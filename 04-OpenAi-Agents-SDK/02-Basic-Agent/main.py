# Import necessary classes and functions from the agents framework
from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig

# For loading environment variables from a .env file
from dotenv import load_dotenv
import os

# Load environment variables from the .env file
load_dotenv()

# Get your Gemini API key from the environment
api_key = os.getenv("GEMINI_API_KEY")

# Create an asynchronous OpenAI-like client, configured for Google's Gemini API
# Note: Youâ€™re overriding the base_url to point to Gemini's API endpoint because open ai agents sdk uses by default open ai client and we are not using open ai key so we can configure gemini here
external_client = AsyncOpenAI(
    api_key=api_key,
    base_url="https://generativelanguage.googleapis.com/v1beta/openai/",  # Gemini-compatible endpoint
)

# Define the language model to be used by your agent
# It connects the `external_client` to a model name that behaves like OpenAI's
model = OpenAIChatCompletionsModel(
    openai_client=external_client, model="gemini-2.0-flash"  # Specify the Gemini model you can another gemini model here
)

# Define the configuration for running the agent
# You specify the model, provider (client), and optionally disable tracing/logging
config = RunConfig(
    model=model,
    model_provider=external_client,
    tracing_disabled=True,  # Disable tracing (can be used for observability/logging if needed) you need to disable it when using gemini because gemini does not support tracing
)

# Create an agent instance
# You must give it a name and a system prompt (instructions)
agent = Agent(
    name="Assistant",  # Name of the agent
    instructions="You are a powerful assistant",  # System prompt or role description
)

# Use Runner to synchronously execute the agent with a user message
# It uses the agent + config + input prompt to generate a response
result = Runner.run_sync(
    agent,
    "Write a haiku about recursion in programming.",  # Input message or query to the agent you can customize it using input 
    run_config=config,
)

# Output the final response generated by the agent
print(result.final_output)
